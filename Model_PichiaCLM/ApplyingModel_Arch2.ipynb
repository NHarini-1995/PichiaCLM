{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b19b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#from DataPrep import data_prep\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import tf_text to load the ops used by the tokenizer saved model\n",
    "#import tensorflow_text  # pylint: disable=unused-import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model,  Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional, Dropout, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding, Concatenate\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Attention\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aee5fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harini/Dropbox (MIT)/Harini Narayanan’s files/1_Home/CodonOptimization/CO_Application/3B2\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a36a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq_Data = pd.read_csv('3B2.csv')\n",
    "AA_ts_seq = Seq_Data.iloc[:,2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30d804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AA_Codon_list():\n",
    "    dic_AA_codon = {'A': ['GCT', 'GCC', 'GCA', 'GCG'],\n",
    "                    'C': ['TGT', 'TGC'],\n",
    "                    'D': ['GAT', 'GAC'],\n",
    "                    'E': ['GAA', 'GAG'],\n",
    "                    'F': ['TTT', 'TTC'],\n",
    "                    'G': ['GGT', 'GGA', 'GGC', 'GGG'],\n",
    "                    'H': ['CAT', 'CAC'],\n",
    "                    'I': ['ATT', 'ATC', 'ATA'],\n",
    "                    'K': ['AAA', 'AAG'],\n",
    "                    'L': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'],\n",
    "                    'M': ['ATG'],\n",
    "                    'N': ['AAT', 'AAC'],\n",
    "                    'P': ['CCT', 'CCC', 'CCA', 'CCG'],\n",
    "                    'Q': ['CAA', 'CAG'],\n",
    "                    'R': ['CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'],\n",
    "                    'S': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'],\n",
    "                    'T': ['ACT', 'ACC', 'ACA', 'ACG'],\n",
    "                    'V': ['GTT', 'GTC', 'GTA', 'GTG'],\n",
    "                    'W': ['TGG'],\n",
    "                    'Y': ['TAT', 'TAC'],\n",
    "                    '*': ['TAA', 'TAG', 'TGA']}\n",
    "\n",
    "    codon_list = []\n",
    "    AA_list = []\n",
    "    for key in dic_AA_codon:\n",
    "        for i in range(len(dic_AA_codon[key])):\n",
    "            AA_list.append(key)\n",
    "        for i in dic_AA_codon[key]:\n",
    "            codon_list.append(i)\n",
    "    return AA_list, codon_list\n",
    "\n",
    "def tokenize_Codon(sequences):\n",
    "    AA_list, codon_list = AA_Codon_list()\n",
    "    keys = codon_list\n",
    "    values = range(1, len(codon_list) + 1)\n",
    "    Codon_dict = dict(zip(keys, values))\n",
    "    seq_tokenized = []\n",
    "    for s in range(len(sequences)):\n",
    "        seq = sequences[s]\n",
    "        temp = [65]  # Start token\n",
    "        for i in range(int(len(seq) / 3)):\n",
    "            temp.append(Codon_dict[seq[3 * i: 3 * (i + 1)]])\n",
    "        \n",
    "        temp.append(66)\n",
    "        seq_tokenized.append(temp)\n",
    "\n",
    "    return seq_tokenized, Codon_dict\n",
    "\n",
    "def tokenize_AA(sequences):\n",
    "    AA_dict = {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10,\n",
    "               'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19,\n",
    "               'Y': 20, 'X': 21, 'Z': 21, 'B': 21, 'U': 21, 'O': 21, '*': 22}\n",
    "\n",
    "    seq_tokenized = []\n",
    "    for s in range(len(sequences)):\n",
    "        seq = sequences[s]\n",
    "        temp = [24]  # Start token\n",
    "        for i in range(len(seq)):\n",
    "            temp.append(AA_dict[seq[i]])\n",
    "        temp.append(23)\n",
    "\n",
    "        seq_tokenized.append(temp)\n",
    "\n",
    "    return seq_tokenized, AA_dict\n",
    "\n",
    "\n",
    "def tokenized_AACodonList():\n",
    "    AA_dict = {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10,\n",
    "               'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19,\n",
    "               'Y': 20, 'X': 21, 'Z': 21, 'B': 21, 'U': 21, 'O': 21, '*': 22}\n",
    "    dic_AA_codon = {'A': ['GCT', 'GCC', 'GCA', 'GCG'],\n",
    "                    'C': ['TGT', 'TGC'],\n",
    "                    'D': ['GAT', 'GAC'],\n",
    "                    'E': ['GAA', 'GAG'],\n",
    "                    'F': ['TTT', 'TTC'],\n",
    "                    'G': ['GGT', 'GGA', 'GGC', 'GGG'],\n",
    "                    'H': ['CAT', 'CAC'],\n",
    "                    'I': ['ATT', 'ATC', 'ATA'],\n",
    "                    'K': ['AAA', 'AAG'],\n",
    "                    'L': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'],\n",
    "                    'M': ['ATG'],\n",
    "                    'N': ['AAT', 'AAC'],\n",
    "                    'P': ['CCT', 'CCC', 'CCA', 'CCG'],\n",
    "                    'Q': ['CAA', 'CAG'],\n",
    "                    'R': ['CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'],\n",
    "                    'S': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'],\n",
    "                    'T': ['ACT', 'ACC', 'ACA', 'ACG'],\n",
    "                    'V': ['GTT', 'GTC', 'GTA', 'GTG'],\n",
    "                    'W': ['TGG'],\n",
    "                    'Y': ['TAT', 'TAC'],\n",
    "                    '*': ['TAA', 'TAG', 'TGA']}\n",
    "    AA_list, codon_list = AA_Codon_list()\n",
    "    token_AA_codon = {}\n",
    "    for i in dic_AA_codon.keys():\n",
    "        token_AA_codon[AA_dict[i]] = []\n",
    "        for j in dic_AA_codon[i]:\n",
    "            token_AA_codon[AA_dict[i]].append(codon_list.index(j)+1)\n",
    "            \n",
    "    return token_AA_codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ead0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_list, codon_list = AA_Codon_list()\n",
    "token_AA_codon = tokenized_AACodonList()\n",
    "token_AA_codon[23] = [66]\n",
    "AA_seq_tokenized, AA_seq_tokenizer = tokenize_AA(AA_ts_seq)\n",
    "AA_pad_seq = pad_sequences(AA_seq_tokenized, maxlen=1001, dtype='int32', padding=\"post\", truncating=\"post\")\n",
    "\n",
    "AA_ts = AA_pad_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a998396",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c973c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harini/Dropbox (MIT)/Harini Narayanan’s files/1_Home/CodonOptimization/CO_Application\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6719b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 01:17:33.279830: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1000, 149)    3725        ['input_1[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 999)]        0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  [(None, 1000, 1026)  2043792     ['embedding[0][0]']              \n",
      "                                , (None, 513),                                                    \n",
      "                                 (None, 513)]                                                     \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 999, 135)     9045        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1026)         0           ['bidirectional[0][1]',          \n",
      "                                                                  'bidirectional[0][2]']          \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    [(None, 999, 1026),  3579714     ['embedding_1[0][0]',            \n",
      "                                 (None, 1026)]                    'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " gru_2 (GRU)                    [(None, 1000, 1026)  3622806     ['embedding[1][0]',              \n",
      "                                , (None, 1026)]                   'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 999, 1026)    0           ['gru_1[0][0]',                  \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 1000, 1026)   0           ['gru_2[0][0]',                  \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 999, 2052)    0           ['gru_1[0][0]',                  \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 1000, 2052)   0           ['gru_2[0][0]',                  \n",
      "                                                                  'attention_1[0][0]']            \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 999, 209)    429077      ['concatenate_1[0][0]']          \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 1000, 205)   420865      ['concatenate_2[0][0]']          \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              multiple             0           ['time_distributed[0][0]',       \n",
      "                                                                  'time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 999, 67)     14070       ['dropout[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 1000, 25)    5150        ['dropout[1][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,128,244\n",
      "Trainable params: 10,128,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1000, 149)    3725        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  [(None, 1000, 1026)  2043792     ['embedding[0][0]']              \n",
      "                                , (None, 513),                                                    \n",
      "                                 (None, 513)]                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1026)         0           ['bidirectional[0][1]',          \n",
      "                                                                  'bidirectional[0][2]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,047,517\n",
      "Trainable params: 2,047,517\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1000, 149)    3725        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1026)]       0           []                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gru_2 (GRU)                    [(None, 1000, 1026)  3622806     ['embedding[2][0]',              \n",
      "                                , (None, 1026)]                   'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1000, 1026)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 1000, 1026)   0           ['gru_2[1][0]',                  \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 1000, 2052)   0           ['gru_2[1][0]',                  \n",
      "                                                                  'attention_1[1][0]']            \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 1000, 205)   420865      ['concatenate_2[1][0]']          \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              multiple             0           ['time_distributed_1[1][0]']     \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 1000, 25)    5150        ['dropout[2][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,052,546\n",
      "Trainable params: 4,052,546\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        multiple             9045        ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 1026)]       0           []                               \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    multiple             3579714     ['embedding_1[1][0]',            \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1000, 1026)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " attention (Attention)          multiple             0           ['gru_1[1][0]',                  \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 1, 2052)      0           ['gru_1[1][0]',                  \n",
      "                                                                  'attention[1][0]']              \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  multiple            429077      ['concatenate_3[0][0]']          \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              multiple             0           ['time_distributed[1][0]']       \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  multiple            14070       ['dropout[3][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,031,906\n",
      "Trainable params: 4,031,906\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Settings = pd.read_csv('../Models/2Target_Pichia/BO_forHyperParameter/Arch1/Round1.csv').iloc[:, 1:]\n",
    "Setting_no = 2\n",
    "\n",
    "\n",
    "Max_length = 1000\n",
    "learning_rate = 0.001\n",
    "batch_size = 150\n",
    "epochs = 100\n",
    "aa_vocab_size = 25\n",
    "dna_vocab_size = 67\n",
    "\n",
    "\n",
    "hidden_size_enc = int(Settings['Enc hidden size'][Setting_no])\n",
    "hidden_size_enc_aa = int(Settings['Enc hidden size'][Setting_no])\n",
    "embedding_size_enc = int(Settings['Enc Embedding size'][Setting_no])\n",
    "embedding_size_dec = int(Settings['Dec Embedding size'][Setting_no])\n",
    "Dense_layer_size = int(Settings['Dense Layer size'][Setting_no])\n",
    "Dense_layer_size_aa = int(Settings['Dense Layer size aa'][Setting_no])\n",
    "\n",
    "drop_rate = Settings['Drop rate'][Setting_no]\n",
    "drop_rate_aa = Settings['Drop rate aa'][Setting_no]\n",
    "\n",
    "    \n",
    "input_sequence = Input(shape=(Max_length,))\n",
    "encod_emb = Embedding(input_dim= aa_vocab_size, output_dim = embedding_size_enc,trainable=True, mask_zero = True)\n",
    "embedding = encod_emb(input_sequence)\n",
    "\n",
    "encoder = Bidirectional(GRU(hidden_size_enc, return_sequences=True, return_state = True),\n",
    "                        merge_mode=\"concat\", weights=None)\n",
    "\n",
    "encoder_sequence, encoder_final_f, encoder_final_b  = encoder(embedding)\n",
    "\n",
    "encoder_final = Concatenate(axis=-1)([encoder_final_f, encoder_final_b])\n",
    "\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(Max_length -1, ))\n",
    "decoder_inputs_aa = Input(shape=(Max_length, ))\n",
    "\n",
    "dex=  Embedding(input_dim = dna_vocab_size, output_dim = embedding_size_dec, trainable=True, mask_zero = True)\n",
    "\n",
    "\n",
    "final_dex= dex(decoder_inputs)\n",
    "final_dex_aa =  encod_emb(decoder_inputs_aa)\n",
    "\n",
    "\n",
    "decoder = GRU(2*hidden_size_enc, return_sequences = True, return_state = True)\n",
    "decoder_aa =  GRU(2*hidden_size_enc_aa, return_sequences = True, return_state = True)\n",
    "\n",
    "decoder_sequence, decoder_final = decoder(final_dex, initial_state=encoder_final)\n",
    "decoder_sequence_aa, decoder_final_aa = decoder_aa(final_dex_aa, initial_state=encoder_final)\n",
    "\n",
    "\n",
    "attn_layer = Attention()\n",
    "attn_out = attn_layer([decoder_sequence, encoder_sequence])\n",
    "attn_layer_aa = Attention()\n",
    "attn_out_aa = attn_layer_aa([decoder_sequence_aa, encoder_sequence])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1)([decoder_sequence, attn_out]) #decoder_sequence, \n",
    "decoder_concat_input_aa = Concatenate(axis=-1)([decoder_sequence_aa, attn_out_aa]) #decoder_sequence,\n",
    "\n",
    "\n",
    "Intermediate_layer = TimeDistributed(Dense(Dense_layer_size, activation='tanh'))\n",
    "Intermediate_layer_aa= TimeDistributed(Dense(Dense_layer_size_aa, activation='tanh'))\n",
    "\n",
    "Intemediate_output = Intermediate_layer(decoder_concat_input) #decoder_concat_input\n",
    "Intemediate_output_aa = Intermediate_layer_aa(decoder_concat_input_aa) #decoder_concat_input\n",
    "\n",
    "\n",
    "dropout_layer = Dropout(drop_rate)\n",
    "dropout_output = dropout_layer(Intemediate_output)\n",
    "\n",
    "dropout_layer_aa = Dropout(drop_rate_aa)\n",
    "dropout_output_aa = dropout_layer(Intemediate_output_aa)\n",
    "\n",
    "dense_layer = TimeDistributed(Dense(dna_vocab_size, activation='softmax'))\n",
    "logits = dense_layer(dropout_output)\n",
    "\n",
    "dense_layer_aa = TimeDistributed(Dense(aa_vocab_size, activation='softmax'))\n",
    "logits_aa = dense_layer_aa(dropout_output_aa)\n",
    "\n",
    "enc_dec_model = Model([input_sequence, decoder_inputs, decoder_inputs_aa], [logits, logits_aa])\n",
    "\n",
    "enc_dec_model.compile(loss=sparse_categorical_crossentropy,\n",
    "              optimizer=Adam(learning_rate = learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "enc_dec_model.summary()\n",
    "\n",
    "enc_dec_model.load_weights(\"../Models/OptimizedModel_Checkpoints/PichiaData/2Target_AllData/FinArch2_AttnCorr_cp.ckpt\")\n",
    "\n",
    "after = encod_emb.get_weights()[0]\n",
    "\n",
    "encoder_model = Model(input_sequence, [encoder_final, encoder_sequence])\n",
    "encoder_model.summary()\n",
    "\n",
    "\n",
    "decoder_model_aa = Model([decoder_inputs_aa, encoder_final, encoder_sequence], [logits_aa])\n",
    "\n",
    "decoder_model_aa.summary()\n",
    "\n",
    "encoder_sequence = Input(shape = (Max_length, 2*hidden_size_enc))\n",
    "\n",
    "\n",
    "decoder_states_inputs = Input(shape = (2*hidden_size_enc,))\n",
    "decoder_inputs_inf = Input(shape = (1,)) \n",
    "final_dex2= dex(decoder_inputs_inf)\n",
    "\n",
    "decoder_outputs2, decoder_states2 = decoder(final_dex2, initial_state=decoder_states_inputs)\n",
    "\n",
    "attn_out_inf = attn_layer([decoder_outputs2, encoder_sequence])\n",
    "\n",
    "decoder_concat_input_inf = Concatenate(axis=-1)([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "decoder_out_fin = dense_layer(dropout_layer(Intermediate_layer(decoder_concat_input_inf)))\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_inf, decoder_states_inputs, encoder_sequence],\n",
    "    [decoder_out_fin, decoder_states2])\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91b9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_cds_sequence(input_seq):\n",
    "    #encode the input as state vectors\n",
    "    batch_size = 1\n",
    "    dna_vocab = 67\n",
    "    \n",
    "    final_value, sequence_enc = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    #populate the first character of target sequence with the start character\n",
    "    target_seq[0, 0] = 65\n",
    "\n",
    "    states_value = final_value\n",
    "    stop_condition = False\n",
    "    decoded_sentence = [65] #''\n",
    "    counter = 0\n",
    "    loop_check = 0\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h = decoder_model.predict([target_seq, states_value, sequence_enc])\n",
    "        Mask = np.zeros((1, dna_vocab))\n",
    "        Mask[0, token_AA_codon[input_seq.tolist()[0][counter]]] = 1\n",
    "        output_tokens_modified = np.multiply(output_tokens, Mask)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens_modified )\n",
    "        decoded_sentence.append(sampled_token_index)\n",
    "        counter = counter + 1\n",
    "        appended_index = sampled_token_index\n",
    "  \n",
    "        if (len(decoded_sentence) >= Max_length or appended_index == 66):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        #update states\n",
    "        states_value = h\n",
    "        \n",
    "    \n",
    "        \n",
    "    print(counter)\n",
    "    return decoded_sentence\n",
    "\n",
    "def decode_aa_sequence(input_seq):\n",
    "    \n",
    "    final_value, sequence_enc = encoder_model.predict(input_seq)\n",
    "    output_tokens = decoder_model_aa.predict([input_seq ,final_value, sequence_enc])\n",
    "    \n",
    "    decoded_sentence = []\n",
    "    for i in range(len(input_seq[0])):\n",
    "        sampled_token_index = np.argmax(output_tokens[0,i,:])\n",
    "        decoded_sentence.append(sampled_token_index)\n",
    "        if sampled_token_index ==23:\n",
    "            break\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920414c",
   "metadata": {},
   "source": [
    "#### CDS prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab642386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harini/Dropbox (MIT)/Harini Narayanan’s files/1_Home/CodonOptimization/CO_Application/3B2\n"
     ]
    }
   ],
   "source": [
    "cd 3B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af44a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 01:17:41.681348: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2400 num_cores: 16 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 16777216 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = AA_ts\n",
    "cds_ts_predicted = []\n",
    "offset = 0\n",
    "\n",
    "for seq_index in np.arange(offset+0,len(AA_ts)):#len(AA_ts)  2500,len(AA_ts), offset+500\n",
    "    #take one sequence (part of the training set) for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1, 1:Max_length+1]\n",
    "    decoded_sentence = decode_cds_sequence(input_seq)\n",
    "    cds_ts_predicted.append(decoded_sentence)\n",
    "    \n",
    "\n",
    "pd.DataFrame(cds_ts_predicted).to_excel(\"./PredictedSequences/PichiaArch2_3B2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5867aecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cds_ts_predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0252b61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 01:17:48.504244: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2400 num_cores: 16 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 16777216 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = AA_ts\n",
    "aa_ts_predicted = []\n",
    "\n",
    "for seq_index in np.arange(0, len(AA_ts)):#len(AA_ts)  2500,len(AA_ts)\n",
    "    decoded_sentence_aa = decode_aa_sequence(encoder_input_data[seq_index: seq_index + 1,0:Max_length])\n",
    "    aa_ts_predicted.append(decoded_sentence_aa)\n",
    "    \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = []\n",
    "acc_aa = []\n",
    "for i in np.arange(0, len(AA_ts)): #len(AA_ts) - 2500\n",
    "   \n",
    "    obs_aa = [x for x in AA_ts[i, 1:Max_length+1] if x]\n",
    "    \n",
    "    if len(obs_aa) == len(aa_ts_predicted[i]):\n",
    "        acc_aa.append(accuracy_score(obs_aa, aa_ts_predicted[i]))\n",
    "        #print(accuracy_score(obs, cds_ts_predicted[i]))\n",
    "    else:\n",
    "        acc_aa.append(np.nan)\n",
    "        #print(NaN)\n",
    "\n",
    "pd.DataFrame(acc_aa).to_excel('AA_Check.xlsx','PichiaArch2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f85b1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(acc_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a750cf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa1f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
